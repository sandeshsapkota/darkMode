<!DOCTYPE html>
<html class="theme--night">
<head>
    <meta chartset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>general learning</title>
    <link rel="shortcut icon" href="#"/>
    <link href="https://fonts.googleapis.com/css2?family=Nunito:wght@300;400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="dist/app.css">
</head>
<body>
<main class="content">
    <aside class="sidebar">
        <ul>
            <li><a href="javascript:void(0)" class="sidebar__link">Etymology</a></li>
            <li><a href="javascript:void(0)" class="sidebar__link">Informal definition
            </a></li>
            <li><a href="javascript:void(0)" class="sidebar__link">Formalization</a></li>
            <li>
                <a href="javascript:void(0)" class="sidebar__link"> Euclid's algorithm </a>
                <ul>
                    <li><a href="javascript:void(0)" class="sidebar__link sidebar__link-nested"> Expressing algorithms
                    </a></li>
                    <li><a href="javascript:void(0)" class="sidebar__link sidebar__link-nested"> Implementation
                        description</a></li>
                </ul>
            </li>
            <li><a href="javascript:void(0)" class="sidebar__link"> cryptographic algorithms</a></li>

            <li><a href="javascript:void(0)" class="sidebar__link">Computer algorithms
            </a></li>
        </ul>
    </aside>
    <div class="site-content">
        <header class="flex justify-between">
            <h1>Introduction to mathmatics</h1>
            <div class="theme-toggle theme-toggle-js">
                <span class="moon"></span>
                    <span class="sun"></span>
                    <small class="sun__ray"></small>
                    <small class="sun__ray"></small>
                    <small class="sun__ray"></small>
                    <small class="sun__ray"></small>
                    <small class="sun__ray"></small>
                    <small class="sun__ray"></small>
            </div>
        </header>
        <section class="section first">
            <h2>Etymology</h2>


            <p> The word 'algorithm' has its roots in latinizing the name of mathematician Muhammad ibn Musa
                al-Khwarizmi to
                algorismus.[17][18] Al-Khwārizmī (Arabic: الخوارزمی‎, c. 780–850) was a mathematician, astronomer,
                geographer, and scholar in the House of Wisdom in Baghdad,[11] whose name means 'the native of
                Khwarazm', a
                region that was part of Greater Iran and is now in Uzbekistan.[19][20]

            <p> About 825, al-Khwarizmi wrote an Arabic language treatise on the Hindu–Arabic numeral system, which
                was
                translated into Latin during the 12th century. The manuscript starts with the phrase Dixit Algorizmi
                ('Thus
                spake Al-Khwarizmi'), where "Algorizmi" was the translator's Latinization of Al-Khwarizmi's
                name.[21]
                Al-Khwarizmi was the most widely read mathematician in Europe in the late Middle Ages, primarily
                through
                another of his books, the Algebra.[22] In late medieval Latin, algorismus, English 'algorism', the
                corruption of his name, simply meant the "decimal number system".[23] In the 15th century, under the
                influence of the Greek word ἀριθμός (arithmos), 'number' (cf. 'arithmetic'), the Latin word was
                altered
                to
                algorithmus, and the corresponding English term 'algorithm' is first attested in the 17th century;
                the
                modern sense was introduced in the 19th century.[24]
            <p>
                In English, it was first used in about 1230 and then by Chaucer in 1391. English adopted the French
                term,
                but it wasn't until the late 19th century that "algorithm" took on the meaning that it has in modern
                English.[25]
        </section>
        <section class="section ">
            <h2>Informal definition</h2>
            <p>

                In mathematics and computer science, an algorithm (/ˈælɡərɪðəm/ (About this soundlisten)) is a
                finite
                sequence of well-defined, computer-implementable instructions, typically to solve a class of
                problems or
                to
                perform a computation.[1][2] Algorithms are always unambiguous and are used as specifications for
                performing
                calculations, data processing, automated reasoning, and other tasks.
            </p>
            <p>
                For a detailed presentation of the various points of view on the definition of "algorithm", see
                Algorithm
                characterizations.
            </p>
            <p>
                An informal definition could be "a set of rules that precisely defines a sequence of
                operations",[27][need
                quotation to verify] which would include all computer programs (including programs that do not
                perform
                numeric calculations), and (for example) any prescribed bureaucratic procedure[28] or cook-book
                recipe.[29]
            </p>
            <p>
                In general, a program is only an algorithm if it stops eventually[30] - even though infinite loops
                may
                sometimes prove desirable.</p>

            <p> A prototypical example of an algorithm is the Euclidean algorithm, which is used to determine the
                maximum
                common divisor of two integers; an example (there are others) is described by the flowchart above
                and as
                an
                example in a later section.</p>

            <p> Boolos, Jeffrey & 1974, 1999 offer an informal meaning of the word "algorithm" in the following
                quotation:</p>

            <p> No human being can write fast enough, or long enough, or small enough† ( †"smaller and smaller
                without
                limit
                … you'd be trying to write on molecules, on atoms, on electrons") to list all members of an
                enumerably
                infinite set by writing out their names, one after another, in some notation. But humans can do
                something
                equally useful, in the case of certain enumerably infinite sets: They can give explicit instructions
                for
                determining the nth member of the set, for arbitrary finite n. Such instructions are to be given
                quite
                explicitly, in a form in which they could be followed by a computing machine, or by a human who is
                capable
                of carrying out only very elementary operations on symbols.[31]</p>
        </section>
        <section class="section ">
            <h2>Formalization</h2>
            <p> As an effective method, an algorithm can be expressed within a finite amount of space and time,[3]
                and
                in a
                well-defined formal language[4] for calculating a function.[5] Starting from an initial state and
                initial
                input (perhaps empty),[6] the instructions describe a computation that, when executed, proceeds
                through
                a
                finite[7] number of well-defined successive states, eventually producing "output"[8] and terminating
                at
                a
                final ending state. The transition from one state to the next is not necessarily deterministic; some
                algorithms, known as randomized algorithms, incorporate random input.[9]
        </section>
        <section class="section">
            <h2>An elegant program for Euclid's algorithm</h2>
            <p>In computer systems, an algorithm is basically an instance of logic written in software by software
                developers, to be effective for the intended "target" computer(s) to produce output from given
                (perhaps null) input. An optimal algorithm, even running in old hardware, would produce faster
                results than a non-optimal (higher time complexity) algorithm for the same purpose, running in more
                efficient hardware; that is why algorithms, like computer hardware, are considered technology.</p>

            <section>

                <b>Expressing algorithms</b>
                <p>The word 'algorithm' has its roots in latinizing the name of mathematician Muhammad ibn Musa
                    al-Khwarizmi
                    to
                    algorismus.[17][18] Al-Khwārizmī (Arabic: الخوارزمی‎, c. 780–850) was a mathematician,
                    astronomer,
                    geographer, and scholar in the House of Wisdom in Baghdad,[11] whose name means 'the native of
                    Khwarazm', a
                    region that was part of Greater Iran and is now in Uzbekistan.[19][20]</p>

                <p> Algorithms are essential to the way computers process data. Many computer programs contain
                    algorithms
                    that
                    detail the specific instructions a computer should perform—in a specific order—to carry out a
                    specified
                    task, such as calculating employees' paychecks or printing students' report cards. Thus, an
                    algorithm
                    can be
                    considered to be any sequence of operations that can be simulated by a Turing-complete system.
                    Authors
                    who
                    assert this thesis include Minsky (1967), Savage (1987) and Gurevich (2000):</p>
            </section>
            <section>
                <b>Implementation description</b>
                <p>Minsky: "But we will also maintain, with Turing … that any procedure which could "naturally" be
                    called
                    effective, can, in fact, be realized by a (simple) machine. Although this may seem extreme, the
                    arguments …
                    in its favor are hard to refute".[37]</p>

                <p> Gurevich: “… Turing's informal argument in favor of his thesis justifies a stronger thesis:
                    every
                    algorithm
                    can be simulated by a Turing machine … according to Savage [1987], an algorithm is a
                    computational
                    process
                    defined by a Turing machine".[38]</p>

                <p> Turing machines can define computational processes that do not terminate. The informal
                    definitions
                    of
                    algorithms generally require that the algorithm always terminates. This requirement renders the
                    task
                    of
                    deciding whether a formal procedure is an algorithm impossible in the general case—due to a
                    major
                    theorem of
                    computability theory known as the halting problem.</p>
            </section>

        </section>
        <section class="section">
            <h2>Cryptographic algorithms</h2>
            <p> the 9th century used cryptographic algorithms for code-breaking, based on frequency
                analysis.[13] The concept of algorithm has existed since antiquity. Arithmetic algorithms, such as a
                division algorithm,
                was used by ancient Babylonian mathematicians c. 2500 BC and Egyptian mathematicians c. 1550 BC.[10]
                Greek
                mathematicians later used algorithms in the sieve of Eratosthenes for finding prime numbers,[11] and
                the
                Euclidean algorithm for finding the greatest common divisor of two numbers.[12] Arabic
                mathematicians
                such
                as al-Kindi in</p>

            <p> An "enumerably infinite set" is one whose elements can be put into one-to-one correspondence with
                the
                integers. Thus Boolos and Jeffrey are saying that an algorithm implies instructions for a process
                that
                "creates" output integers from an arbitrary "input" integer or integers that, in theory, can be
                arbitrarily
                large. For example, an algorithm can be an algebraic equation such as y = m + n (i.e., two arbitrary
                "input
                variables" m and n that produce an output y), but various authors' attempts to define the notion
                indicate
                that the word implies much more than this, something on the order of (for the addition example):</p>

            <p> Precise instructions (in language understood by "the computer")[32] for a fast, efficient,
                "good"[33]
                process that specifies the "moves" of "the computer" (machine or human, equipped with the necessary
                internally contained information and capabilities)[34] to find, decode, and then process arbitrary
                input
                integers/symbols m and n, symbols + and = … and "effectively"[35] produce, in a "reasonable"
                time,[36]
                output-integer y at a specified place and in a specified format.
                The concept of algorithm is also used to define the notion of decidability—a notion that is central
                for
                explaining how formal systems come into being starting from a small set of axioms and rules. In
                logic,
                the
                time that an algorithm requires to complete cannot be measured, as it is not apparently related to
                the
                customary physical dimension. From such uncertainties, that characterize ongoing work, stems the
                unavailability of a definition of algorithm that suits both concrete (in some sense) and abstract
                usage
                of
                the term.</p>
        </section>
        <section class="section ">
            <h2>Computer algorithms</h2>
            <p> The word algorithm itself is derived from the 9th-century mathematician Muḥammad ibn Mūsā
                al-Khwārizmī,
                Latinized Algoritmi.[14] A partial formalization of what would become the modern concept of
                algorithm
                began
                with attempts to solve the Entscheidungsproblem (decision problem) posed by David Hilbert in 1928.
                Later
                formalizations were framed as attempts to define "effective calculability"[15] or "effective
                method".[16]
                Those formalizations included the Gödel–Herbrand–Kleene recursive functions of 1930, 1934 and 1935,
                Alonzo
                Church's lambda calculus of 1936, Emil Post's Formulation 1 of 1936, and Alan Turing's Turing
                machines
                of
                1936–37 and 1939.</p>
        </section>
    </div>
</main>

<script src="src/js/app.js"></script>
</body>
</html>